# -*- coding: utf-8 -*-
"""Lab2_03121098.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wKmOpycSy4ymdGhtm9Jjwz2T8fS5S08X

#2η ομαδική εργασία στη Τεχνολογία και Ανάλυση Εικόνων και Βίντεο

Ονοματεπώνυμο: **Λάππας Νικόλαος**

ΑΜ: **03121098**

## Θεωρητικό Μέρος

Αφού μελετήσαμε τα άρθρα που μας δόθηκαν, καλούμαστε να παραθέσουμε συγκεντρωτικά ορισμένα στοιχεία σε έναν πίνακα, σχετικά με τα διαφορετικά Neural Networks που παρουσιάστηκαν στα άρθρα αυτά.

### Πίνακας CNN Αρχιτεκτονικών

| Χαρακτηριστικό               | LeNet                               | AlexNet                                            | VGG                                     |
|-----------------------------|-------------------------------------|----------------------------------------------------|-----------------------------------------|
| **Επίπεδα**                 | 7 (2×Conv, 2×Pool, 3×FC)            | 11 (5×Conv, 3×Pool, 3×FC)        | 16 (8×Conv, 5×Pool, 3×FC)                     |
| **Μέγεθος Φίλτρων**         | 5×5                                 | 11×11×3, 5×5×3, 3×3×3                            | 3×3                                     |
| **Ενεργοποίηση**            | Sigmoid                             | ReLU                                               | ReLU                                    |
| **Dropout**                 | Όχι                                 | Ναι (στα FC)                                       | Ναι (στα FC)                            |
| **Pooling**                 | Average (2×2)                       | Max (3×3, stride 2)                                | Max (2×2, stride 2)                     |
| **Παράμετροι**              | 2578 (independent)                  | ~60M                                               | ~138M                                   |
| **Κανονικοποίηση**          | Όχι                                 | LRN (σε κάποιες conv layers)                      | Όχι (ήπια χρήση σε κάποια εκδοχή)       |
| **Input Μέγεθος**           | 28×28 grayscale                     | 224×224 RGB                                        | 224×224 RGB                             |

**Σχολιασμός:** Παρατηρούμε, αρχικά, ότι το δίκτυο **LeNet** είναι αυτό που διαφέρει περισσότερο από τα υπόλοιπα, και αυτό αιτιολογείται από το ότι υλοποιήθηκε παλαιότερα από τα άλλα. Συγκεκριμένα βλέπουμε ότι είναι το μόνο που χρησιμοποιεί την sigmoid ως συνάρτηση ενεργοποίησης, και πως δεν χρησιμοποιεί την τεχνική dropout. Βλέπουμε, επίσης, ότι έχει το μικρότερο βάθος συγκριτικά με τα άλλα δυο. Το νευρωνικό αυτό ωστόσο, ήταν πρωταρχικό για την εποχή του, αλλά περιορίζεται σε απλά tasks όπως η αναγνώριση ψηφίων.

Τα δίκτυα **AlexNet** και **VGG** χρησιμοποιούν και τα δύο την ReLU σαν συνάρτηση ενεργοποίησης, κάτι που συμβάλει στην ακρίβεια των μοντέλων και στην ταχύτερη εκπαίδευσή τους. Αυτό έδωσε την δυνατότητα στην ανάπτυξη βαθύτερων νευρωνικών, όπως το very Deep VGG, τα οποία όπως απέδειξαν οι συντάκτες του άρθρου με τίτλο "VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION", οδηγούν σε πολύ καλύτερα και ακριβή αποτελέσματα, όχι μόνο στο συγκεκριμένο dataset με το οποίο ασχολήθηκαν, αλλά και σε διαφορετικής έκτασης dataset.

Τα τελευταία δυο νευρωνικά κάνουν επιπλέον χρήση της dropout τεχνικής, μια τεχνική regularization, με την οποία με πιθανότητα 0.5 ορισμένοι νευρώνες του δικτύου σταματάνε να επιδρούν τόσο στο forward pass όσο και στο back-propagation για την εκάστοτε εποχή. Αποτέλεσμα αυτού είναι η αποφυγή του overfitting, αφού παύει να βασίζεται σε συγκερκιμένους μόνο νευρώνες το νευρωνικό. Παράλληλα, τα δυο αυτά νευρωνικά κάνουν χρήση της max pooling τεχνικής η οποία είναι πιο discriminative σε σχέση με την average pooling που έχει σαν αποτέλεσμα μια περισσότερο γενική αναπαράσταση του αποτελέσματος.

Τέλος, το **VGG** φαίνεται να έχει προκαλέσει την μεγαλύτερη επανάσταση από τις τρεις αυτές διαφορετικές αρχιτεκτονικές για νευρωνικό δίκτυο. Ερευνητές έχουν χρησιμοποιήσει την δομή του και βασίζονται στο ότι βαθύτερα νευρωνικά με μικρότερα (3×3) convolutional filters μπορούν να αποδώσουν καλύτερα και πιο λεπτομερή χαρακτηριστικά και μοτίβα μιας εικόνας. Ωστόσο μια τέτοια προσέγγιση συνοδεύεται από χρήση αριθμητικά περισσότερων παραμέτρων σε σχέση με τα **LeNet** και **AlexNet**.

## Υλοποίηση Αλγορίθμου
"""

!pip install tensorflow

"""### Εισαγωγή και επισκόπηση του συνόλου δεδομένων"""

from __future__ import absolute_import, division, print_function, unicode_literals # legacy compatibility

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# helper functions

# select from from_list elements with index in index_list
def select_from_list(from_list, index_list):
  filtered_list= [from_list[i] for i in index_list]
  return(filtered_list)

# append in filtered_list the index of each element of unfilterd_list if it exists in in target_list
def get_ds_index(unfiliterd_list, target_list):
  index = 0
  filtered_list=[]
  for i_ in unfiliterd_list:
    if i_[0] in target_list:
      filtered_list.append(index)
    index += 1
  return(filtered_list)

# load the entire dataset
import tensorflow as tf
from tensorflow.keras import datasets, layers, models

(x_train_all, y_train_all), (x_test_all, y_test_all) = tf.keras.datasets.cifar100.load_data(label_mode='fine')

print(x_train_all.shape)

"""Η κάθε ομάδα θα δουλέψει με διαφορετικό υποσύνολο του dataset.
Στο επόμενο κελί, αντικαταστήστε την τιμή της μεταβλητής `team_seed` με τον αριθμό που αντιστοιχεί στην ομάδας σας.
"""

# REPLACE WITH YOUR TEAM NUMBER
team_seed = 98

# select from CIFAR100 20 classes
cifar100_classes_url = "https://pastebin.com/raw/nzE1n98V"

import requests
from io import StringIO

headers = {'User-Agent': 'Mozilla/5.0'}
response = requests.get(cifar100_classes_url, headers=headers)

if response.status_code == 200:
    team_classes = pd.read_csv(StringIO(response.text), sep=',', header=None)
    print("Successfully loaded team_classes")
else:
    raise Exception(f"Failed to fetch team_classes: {response.status_code}")

labels_url = 'https://pastebin.com/raw/qgDaNggt'
headers = {'User-Agent': 'Mozilla/5.0'}

response = requests.get(labels_url, headers=headers)

if response.status_code == 200:
    CIFAR100_LABELS_LIST = pd.read_csv(StringIO(response.text), sep=',', header=None).astype(str).values.tolist()[0]
    print("CIFAR-100 label list loaded")
else:
    raise Exception(f"Failed to fetch label list: {response.status_code}")

"""Δημιουργούμε το μοναδικό dataset της ομάδας μας:"""

# team_classes = pd.read_csv(cifar100_classes_url, sep=',', header=None)
# CIFAR100_LABELS_LIST = pd.read_csv('https://pastebin.com/raw/qgDaNggt', sep=',', header=None).astype(str).values.tolist()[0]

our_index = team_classes.iloc[team_seed,:].values.tolist()
our_classes = select_from_list(CIFAR100_LABELS_LIST, our_index)
train_index = get_ds_index(y_train_all, our_index)
test_index = get_ds_index(y_test_all, our_index)

x_train_ds = np.asarray(select_from_list(x_train_all, train_index))
y_train_ds = np.asarray(select_from_list(y_train_all, train_index))
x_test_ds = np.asarray(select_from_list(x_test_all, test_index))
y_test_ds = np.asarray(select_from_list(y_test_all, test_index))

# print our classes
print(our_classes)

print(x_train_ds[1].shape)

# get (train) dataset dimensions
data_size, img_rows, img_cols, img_channels = x_train_ds.shape

# set validation set percentage (wrt the training set size)
validation_percentage = 0.15
val_size = round(validation_percentage * data_size)

# Reserve val_size samples for validation and normalize all values
x_val = x_train_ds[-val_size:]/255
y_val = y_train_ds[-val_size:]
x_train = x_train_ds[:-val_size]/255
y_train = y_train_ds[:-val_size]
x_test = x_test_ds/255
y_test = y_test_ds

# summarize loaded dataset
print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))
print('Validation: X=%s, y=%s' % (x_val.shape, y_val.shape))
print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))

# get class label from class index
def class_label_from_index(fine_category):
  return(CIFAR100_LABELS_LIST[fine_category.item(0)])

# plot first few images
plt.figure(figsize=(6, 6))
for i in range(9):
	# define subplot
  plt.subplot(330 + 1 + i).set_title(class_label_from_index(y_train[i]))
	# plot raw pixel data
  plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))
  #show the figure
  plt.axis('off')
plt.show()

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()

# Fit and transform the labels for each dataset
y_val_to20 = label_encoder.fit_transform(y_val)
y_train_to20 = label_encoder.transform(y_train)
y_test_to20 = label_encoder.transform(y_test)

print(y_val_to20[1])
print(y_val[1])
print(y_test_to20[1].shape)
print(y_val[1].shape)

print(y_val_to20)

"""## Ερώτημα 1
---
### Βήμα 1: Σχεδίαση και εκπαίδευση των μοντέλων

 Σχεδίαστε και εκπαιδεύστε τα μοντέλα  **LeNet, AlexNet και  VGG**, καθώς και ένα δικό σας μοντέλο (ονομάστε το π.χ. **MyCNN**) χρησιμοποιώντας τον ίδιο αλγορίθμο βελτιστοποίησης ([optimizer](https://keras.io/api/optimizers/)), την ίδια συνάρτηση κόστους [loss function](https://keras.io/api/losses/), το ίδιο μέγεθος παρτίδας (batch size) και 50 εποχές (epochs) `*`.

 Για την εκτίμηση της απόδοσης των μοντέλων να χρησιμοποιήσετε ως μετρική ([metrics](https://keras.io/api/metrics/)) την F1-score.


`*`
 Μπορείτε να πειραματιστείτε με τον optimizer, την loss function και το batch size για τα 4 μοντέλα πριν καταλήξετε στην τελική σας κοινή, για όλα τα μοντέλα επιλογή.


---
  
### Βήμα 2: Αξιολόγηση των μοντέλων

α. Για κάθε ένα από τα μοντέλα που εκπαιδεύσατε στο Βήμα 1, απεικονίστε σε κοινό διάγραμμα τα F1-scores εκπαίδευσης και επικύρωσης στο σύνολο των εποχών.

β. Αξιολογήστε, αναλυτικά, τα αποτελέσματά σας ως προς τα εξής:
 - Επίδραση του πλήθους των δεδομένων/κλάσεων.
 - Επίδραση του αλγόριθμου βελτιστοποίησης (optimizer)
 - Επίδραση του μεγέθους δέσμης (batch size)
---

### Βήμα 3: Αξιολόγηση F1-score
Αξιολογήστε τα F1-scores, χρησιμοποιώντας το σύνολο ελέγχου σας (test set).

---

**Υλοποίηση Βήμα 1**
"""

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

"""**LeNet**"""

# LeNet Architecture
def LeNet_NN():
  model = models.Sequential([
      layers.Conv2D(filters=6, kernel_size=5, activation='sigmoid', padding='same'),
      layers.AvgPool2D(pool_size=2, strides=2),
      layers.Conv2D(filters=16, kernel_size=5, activation='sigmoid'),
      layers.AvgPool2D(pool_size=2, strides=2),
      layers.Flatten(),
      layers.Dense(units=120, activation='sigmoid'),
      layers.Dense(units=84, activation='sigmoid'),
      layers.Dense(20, activation="softmax")
  ])
  return model

print("Layer Output Shapes:")
X = tf.random.uniform((1, 28, 28, 1))
for layer in LeNet_NN().layers:
  X = layer(X)
  print(f"{layer.__class__.__name__:<20} output shape:\t{X.shape}")

def preprocess_images(images, target_size=(28, 28)):
  # Convert to grayscale
  images_gray = tf.image.rgb_to_grayscale(images)
  # Resize
  images_resized = tf.image.resize(images_gray, target_size)
  return images_resized

x_train_resized28 = preprocess_images(x_train)
x_val_resized28 = preprocess_images(x_val)
x_test_resized28 = preprocess_images(x_test)

# Training Set 1 (Trained with CPU)
from tensorflow.keras.optimizers import SGD

sgd_optimizer = SGD(learning_rate=0.1, momentum=0.9)

LeNet_model1 = LeNet_NN()
LeNet_model1.compile(
    optimizer=sgd_optimizer,
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)
LeNet_results1 = LeNet_model1.fit(
    x_train, y_train_to20, epochs=50, batch_size=10, validation_data=(x_val, y_val_to20)
)

# Training Set 2 (Trained with CPU)
LeNet_model2 = LeNet_NN()
LeNet_model2.compile(
    optimizer='Nadam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)
LeNet_results2 = LeNet_model2.fit(
    x_train, y_train_to20, epochs=50, batch_size=128, validation_data=(x_val, y_val_to20)
)

# Training Set 1 (Trained with GPU)
from tensorflow.keras.optimizers import SGD

sgd_optimizer = SGD(learning_rate=0.1, momentum=0.9)

LeNet_model1 = LeNet_NN()
LeNet_model1.compile(
    optimizer=sgd_optimizer,
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)
LeNet_results1 = LeNet_model1.fit(
    x_train_resized28, y_train_to20, epochs=50, batch_size=10, validation_data=(x_val_resized28, y_val_to20)
)

# Training Set 2 (Trained with GPU)
LeNet_model2 = LeNet_NN()
LeNet_model2.compile(
    optimizer='Nadam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)
LeNet_results2 = LeNet_model2.fit(
    x_train_resized28, y_train_to20, epochs=50, batch_size=128, validation_data=(x_val_resized28, y_val_to20)
)

# Training Set 3 (Trained with GPU)
LeNet_model3 = LeNet_NN()
LeNet_model3.compile(
    optimizer='RMSprop',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)
LeNet_results3 = LeNet_model3.fit(
    x_train_resized28, y_train_to20, epochs=50, batch_size=10, validation_data=(x_val_resized28, y_val_to20)
)

"""**AlexNet**"""

# AlexNet Architecture
def AlexNet_NN():
  model = models.Sequential([
      layers.Conv2D(filters=96, kernel_size=11, strides=4, activation='relu'),
      layers.MaxPool2D(pool_size=3, strides=2),
      layers.Conv2D(filters=256, kernel_size=5, activation='relu', padding='same'),
      layers.MaxPool2D(pool_size=3, strides=2),
      layers.Conv2D(filters=384, kernel_size=3, activation='relu', padding='same'),
      layers.Conv2D(filters=384, kernel_size=3, activation='relu', padding='same'),
      layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),
      layers.MaxPool2D(pool_size=3, strides=2),
      layers.Flatten(),
      layers.Dense(units=4096, activation='relu'),
      layers.Dropout(0.5),
      layers.Dense(units=4096, activation='relu'),
      layers.Dropout(0.5),
      layers.Dense(20, activation="softmax")
  ])
  return model

print("Layer Output Shapes:")
Y = tf.random.uniform((1, 224, 224, 3))
for layer in AlexNet_NN().layers:
  Y = layer(Y)
  print(f"{layer.__class__.__name__:<20} output shape:\t{Y.shape}")

def resize_images(images, target_size=(224, 224)):
  return tf.image.resize(images, target_size)

x_train_resized = resize_images(x_train)
x_val_resized = resize_images(x_val)
x_test_resized = resize_images(x_test)

# Training Set 1
AlexNet_model1 = AlexNet_NN()
AlexNet_model1.compile(
    optimizer='SGD',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)
AlexNet_results1 = AlexNet_model1.fit(
    x_train_resized, y_train_to20, epochs=50, batch_size=10, validation_data=(x_val_resized, y_val_to20)
)

# Training Set 2
AlexNet_model2 = AlexNet_NN()
AlexNet_model2.compile(
    optimizer='Adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)
AlexNet_results2 = AlexNet_model2.fit(
    x_train_resized, y_train_to20, epochs=50, batch_size=128, validation_data=(x_val_resized, y_val_to20)
)

"""**VGG**"""

# VGG Architecture
def VGG_NN():
  model = models.Sequential([
      # Convolutional Blocks
      layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', input_shape=(224, 224, 3)),
      layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),
      layers.MaxPool2D(pool_size=2, strides=2),

      layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'),
      layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'),
      layers.MaxPool2D(pool_size=2, strides=2),

      layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'),
      layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'),
      layers.MaxPool2D(pool_size=2, strides=2),

      layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu'),
      layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu'),
      layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu'),
      layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu'),
      layers.MaxPool2D(pool_size=2, strides=2),

      # Flatten and Fully Connected layers
      # layers.Flatten(), # I did not have the computational power for the amount of parameters
      layers.GlobalAveragePooling2D(), # Almost the same as doing the Flatten() ...
      layers.Dense(units=4096, activation='relu'),
      layers.Dropout(0.5),
      layers.Dense(units=4096, activation='relu'),
      layers.Dropout(0.5),
      layers.Dense(20, activation="softmax")
  ])
  return model

print("Layer Output Shapes:")
Z = tf.random.uniform((1, 224, 224, 3))
for layer in VGG_NN().layers:
  Z = layer(Z)
  print(f"{layer.__class__.__name__:<20} output shape:\t{Z.shape}")

# Training Set 1
VGG_model1 = VGG_NN()
VGG_model1.compile(
    optimizer='SGD',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)
VGG_results1 = VGG_model1.fit(
    x_train_resized, y_train_to20, epochs=50, batch_size=10, validation_data=(x_val_resized, y_val_to20)
)

# Training Set 2
VGG_model2 = VGG_NN()
VGG_model2.compile(
    optimizer='Adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)
VGG_results2 = VGG_model2.fit(
    x_train_resized, y_train_to20, epochs=50, batch_size=128, validation_data=(x_val_resized, y_val_to20)
)

"""**MyCNN**"""

def MyCNN():
  model = models.Sequential([
      # Block 1
      layers.Conv2D(32, kernel_size=5, padding='same', activation='relu', input_shape=(32, 32, 3)),
      layers.MaxPooling2D(pool_size=2, strides=2),

      # Block 2
      layers.Conv2D(64, kernel_size=3, padding='same', activation='relu'),
      layers.MaxPooling2D(pool_size=2, strides=2),

      # Block 3
      layers.Conv2D(128, kernel_size=3, padding='same', activation='relu'),
      layers.MaxPooling2D(pool_size=2, strides=2),

      # Fully Connected Layers
      layers.Flatten(),
      layers.Dropout(0.5),
      layers.Dense(256, activation='relu'),
      layers.Dense(20)  # 20 classes output
  ])
  return model

print("Layer Output Shapes:")
P = tf.random.uniform((1, 32, 32, 3))
for layer in MyCNN().layers:
  P = layer(P)
  print(f"{layer.__class__.__name__:<20} output shape:\t{P.shape}")

# Training Set 1
MyCNN_model1 = MyCNN()
MyCNN_model1.compile(
    optimizer='SGD',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=['accuracy']
)
MyCNN_results1 = MyCNN_model1.fit(
    x_train, y_train_to20, epochs=50, batch_size=10, validation_data=(x_val, y_val_to20)
)

# Training Set 2
MyCNN_model2 = MyCNN()
MyCNN_model2.compile(
    optimizer='Adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=['accuracy']
)
MyCNN_results2 = MyCNN_model2.fit(
    x_train, y_train_to20, epochs=50, batch_size=128, validation_data=(x_val, y_val_to20)
)

"""**Δεύτερη εκδοχή δικού μου μοντέλου για πειραματισμό:**

Σύγκριση Αρχικού MyCNN με Βελτιωμένο MyCNN_2

|Σύγκριση                    | MyCNN                        |MyCNN_2                            | Αποτέλεσμα                                         |
|----------------------------|-------------------------------------|---------------------------------------------|--------------------------------------------------------------------|
| **Αριθμός φίλτρων**        | 32 → 64 → 128                        | 64 → 128 → 256                               | Μαθαίνει πιο σύνθετα χαρακτηριστικά                                |
| **Batch Normalization**    | ΟΧΙ                                   | Μετά από κάθε Conv                        | Σταθεροποιεί την εκπαίδευση, μειώνει overfitting                   |
| **Dropout**                | Μόνο μετά το Flatten (0.5)          | Σε κάθε block (0.25–0.5)                     | Περιορίζει το overfitting σταδιακά                                 |
| **Διπλά Conv ανά block**   | ΟΧΙ (1 ανά block)                    | ΝΑΙ (2 ανά block)                             | Βαθύτερη μάθηση ανά επίπεδο, όπως VGG                              |
| **Τελευταίο Dense layer**  | 256 νευρώνες                        | 512 νευρώνες + BatchNorm                    | Πιο πλούσια αναπαράσταση πριν την έξοδο                            |
"""

def MyCNN_2():
    model = models.Sequential([
        layers.Input(shape=(32, 32, 3)),

        # Block 1
        layers.Conv2D(64, 3, padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(64, 3, padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=2),
        layers.Dropout(0.25),

        # Block 2
        layers.Conv2D(128, 3, padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(128, 3, padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=2),
        layers.Dropout(0.25),

        # Block 3
        layers.Conv2D(256, 3, padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=2),
        layers.Dropout(0.4),

        # Fully Connected
        layers.Flatten(),
        layers.Dense(512, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(20)  # Output layer (no softmax if using from_logits=True)
    ])
    return model

print("Layer Output Shapes:")
P = tf.random.uniform((1, 32, 32, 3))
for layer in MyCNN_2().layers:
  P = layer(P)
  print(f"{layer.__class__.__name__:<20} output shape:\t{P.shape}")

"""Παρακάτω χρησιμοποιήθηκε η μετρική **accuracy**."""

# Training Set 1
MyCNN_2_model1 = MyCNN_2()
MyCNN_2_model1.compile(
    optimizer='SGD',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=['accuracy']
)
MyCNN_2_results1 = MyCNN_2_model1.fit(
    x_train, y_train_to20, epochs=50, batch_size=10, validation_data=(x_val, y_val_to20)
)

# Training Set 2
MyCNN_2_model2 = MyCNN_2()
MyCNN_2_model2.compile(
    optimizer='Adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=['accuracy']
)
MyCNN_2_results2 = MyCNN_2_model2.fit(
    x_train, y_train_to20, epochs=50, batch_size=128, validation_data=(x_val, y_val_to20)
)

"""Παρακάτω χρησιμοποιήθηκε η μετρική **f1 score**.

**F1 Score = 2 × (Precision × Recall) / (Precision + Recall)**
"""

from sklearn.metrics import f1_score, precision_score, recall_score
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import Callback

class MetricsCallback(Callback):
    def __init__(self, validation_data):
        super().__init__()
        self.validation_data = validation_data
        # Initialize empty lists to store for plots afterwards
        self.f1_scores = []
        self.precision_scores = []
        self.recall_scores = []

    def on_epoch_end(self, epoch, logs=None): # Automatically called after the end of each training epoch
        x_val, y_val = self.validation_data
        y_pred_logits = self.model.predict(x_val, verbose=0) # raw output of the validation data
        y_pred_classes = np.argmax(y_pred_logits, axis=1) # convert from logits into predicted class labels by selecting the index of the maximum value

        f1 = f1_score(y_val, y_pred_classes, average='macro')
        precision = precision_score(y_val, y_pred_classes, average='macro')
        recall = recall_score(y_val, y_pred_classes, average='macro')

        self.f1_scores.append(f1)
        self.precision_scores.append(precision)
        self.recall_scores.append(recall)

        print(f"\nEpoch {epoch+1} — F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}")

# Training Set 1
MyCNN_2_model1_F1 = MyCNN_2()
MyCNN_2_model1_F1.compile(
    optimizer='SGD',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=['accuracy']
)

metrics1_callback = MetricsCallback(validation_data=(x_val, y_val_to20))

MyCNN_2_results1_F1 = MyCNN_2_model1_F1.fit(
    x_train, y_train_to20, epochs=50, batch_size=10, validation_data=(x_val, y_val_to20), callbacks=[metrics1_callback]
)

plt.figure(figsize=(10, 6))
plt.plot(metrics1_callback.f1_scores, label='F1 Score (macro)', marker='o')
plt.plot(metrics1_callback.precision_scores, label='Precision (macro)', marker='s')
plt.plot(metrics1_callback.recall_scores, label='Recall (macro)', marker='^')
plt.title('F1 / Precision / Recall over Epochs with SGG')
plt.xlabel('Epoch')
plt.ylabel('Score')
plt.legend()
plt.grid(True)
plt.show()

# Training Set 1
MyCNN_2_model2_F1 = MyCNN_2()
MyCNN_2_model2_F1.compile(
    optimizer='Adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=['accuracy']
)

metrics2_callback = MetricsCallback(validation_data=(x_val, y_val_to20))

MyCNN_2_results2_F1 = MyCNN_2_model2_F1.fit(
    x_train, y_train_to20, epochs=50, batch_size=10, validation_data=(x_val, y_val_to20), callbacks=[metrics2_callback]
)

plt.figure(figsize=(10, 6))
plt.plot(metrics2_callback.f1_scores, label='F1 Score (macro)', marker='o')
plt.plot(metrics2_callback.precision_scores, label='Precision (macro)', marker='s')
plt.plot(metrics2_callback.recall_scores, label='Recall (macro)', marker='^')
plt.title('F1 / Precision / Recall over Epochs with Adam')
plt.xlabel('Epoch')
plt.ylabel('Score')
plt.legend()
plt.grid(True)
plt.show()

"""**Plot the Results with accuracy as metric**"""

def plot_accuracy(history, model_name):
  '''
  Parameters:
  :params history: keras history object returned by model.fit()
  :params model_name: the name for the plot title
  '''

  acc = history.history.get('accuracy')
  val_acc = history.history.get('val_accuracy')

  if acc is None or val_acc is None:
    print("Error: 'accuracy' or 'val_accuracy' not found in history.")
    return

  plt.figure(figsize=(10, 6))
  plt.plot(acc, label='Training Accuracy')
  plt.plot(val_acc, label='Validation Accuracy')
  plt.title(f'{model_name} Accuracy')
  plt.xlabel('Epoch')
  plt.ylabel('Accuracy')
  plt.legend()
  plt.grid(True)
  plt.show()

# For LeNet
plot_accuracy(LeNet_results1, model_name="LeNet_model1") # SGD
plot_accuracy(LeNet_results2, model_name="LeNet_model2") # Nadam
plot_accuracy(LeNet_results3, model_name="LeNet_model3") # RMSprop

# For AlexNet
plot_accuracy(AlexNet_results1, model_name="AlexNet_model1") # SGD
plot_accuracy(AlexNet_results2, model_name="AlexNet_model2") # Adam

# For VGG
plot_accuracy(VGG_results1, model_name="VGG_model1") # SGD

plot_accuracy(VGG_results2, model_name="VGG_model2") # Adam

# For MyCNN
plot_accuracy(MyCNN_results1, model_name="MyCNN_model1") # SGD
plot_accuracy(MyCNN_results2, model_name="MyCNN_model2") # Adam

# For MyCNN_2
plot_accuracy(MyCNN_2_results1, model_name="MyCNN_2_model1") # SGD
plot_accuracy(MyCNN_2_results2, model_name="MyCNN_2_model2") # Adam

"""**Σχολιασμός Αποτελεσμάτων:**

Εκτελέσαμε έναν αριθμό από trainings/validations για τα 4 διαφορετικά μοντέλα που υλοποιήσαμε και συγκεκριμένα, για το κάθε μοντέλο πειραματιστήκαμε με διαφορετικούς αλγορίθμους βελτιστοποίησης (*optimizers*), και διαφορετικό *batch size* κρατώντας την ίδια αντιστοιχία για κάθε μοντέλο.

*Τα Plot που κάναμε αφορούν μόνο την εκπαίδευση με GPUs.*

Για το **LeNet** πραγματοποιήσαμε 5 training/validation για 50 εποχές το καθένα. Τα πρώτα δυο έγιναν με χρήση CPU, κάτι που χρειάστηκε πάρα πολύ χρόνο για να τερματίσουν. Τα υπόλοιπα 3 έγιναν με χρήση της T4 GPU σε πολύ λιγότερο χρόνο. Χρησιμοποιήσαμε τους εξείς *optimizers*:
  - SGD (Stochastic Gradient Descent)
  - Nadam (Nesterov-accelerated Adaptive Moment Estimation)
  - RMSprop (Root Mean Square Propagation)

Ο μεν πρώτος *(SGD)* ενημερώνει τα βάρη με βάση το αρνητικό της παραγώγου (κλίσης) του σφάλματος για κάθε batch (ομάδα δειγμάτων). Ο δεύτερος*(Nadam)* είναι ένας συνδυασμός των Adam Και Nesterov momentum, και χρησιμοποιεί προσαρμοστικό leraning rate όπως ο Adam ενσωματώνοντας momentum estimation, προβλέποντας προς τα πού πηγαίνει το βάρος και διορθώνοντας νωρίτερα. Ο δε τρίτος *(RMSprop)* προσαρμόζει το learning rate ξεχωριστά για κάθε βάρος, βασισμένο στο μέσο όρο των πρόσφατων τιμών των παραγώγων.

Επιπλέον, η εκπαίδευση με SGD και RMSprop έγινε με batch size ίσο με 10, ενώ για το Nadam ίσο με 128. Το **batch size** δηλώνει τον αριθμό των δειγμάτων που θα επεξεργαστεί το μοντέλο προτού ανανεώσει τα βάρη. Μεγάλο batch size συνεπάγεται μικρότερες ανανεώσεις βαρών ανά εποχή. **Όπως παρατηρήσαμε, μικρότερο batch size μας έδωσε καλύτερα αποτελέσματα γενικά**.

Καλύτερο αποτέλεσμα πήραμε με το RMSprop *(accuracy: 0.4467 | val_accuracy: 0.2980)*, ενώ με τον SGD φάνηκε να δίνει πολύ άσχημα αποτελέσματα *(accuracy: 0.0483 | val_accuracy: 0.0487)*.

Για τα επόμενα τρία μοντέλα χρησιμοποιήσαμε τους *optimizers*:
  - Adam
  - SGD

Για το **AlexNet** πραγματοποιήσαμε 2 training/validation για 50 εποχές το καθένα (μόνο με χρήση T4 GPU). Αυτό που παρατηρήσαμε ήταν ότι αρχικά, για τις πρώτες εποχές το *validation accuracy* αυξανόταν σχεδόν όσο και το *accuracy*. Ωστόσο, ενώ το *accuracy* κατέληγε πολύ κοντά στο 1 (100%), το *val accuracy* έφτανε την τιμή 0.6067 (με τον SGD και batch size=10), ενώ 0.4433 (με τον Adam και batch size=128). Προέκυψε, δηλαδή, κάτι σαν υπερπροσαρμογή στα δεδομένα εκπαίδευσης.

Για το **VGG** πραγματοποιήσαμε 1 training/validation (λόγω περιορισμένων πόρων) για 50 εποχές το καθένα (μόνο με χρήση T4 GPU). Αυτό που παρατηρήσαμε ήταν ότι αρχικά, για τις πρώτες εποχές (περισσότερες από αυτές του AlexNet), το validation accuracy αυξανόταν σχεδόν όσο και το accuracy. Στην τελευταία επανάληψη (εποχή=50), το *accuracy* κατέληγε στην τιμή 0.6820, ενώ το *val_accuracy* κατέληγε στην τιμή 0.5613 (με τον SGD και batch size=10).

Σύγκριση **MyCNN** και **MyCNN_2**: <br>
Τα δυο αυτά μοντέλα προσπάθησαν να ενσωματώσουν τα καλύτερα χαρακτηριστικά των τριών προηγούμενων, και συγκεκριμένα το MyCNN_2 αποτελεί βελτίωση του MyCNN που υλοποίησα πρώτο, και για αυτό τον λόγο μας δίνει καλύτερα αποτελέσματα. Το νεότερο CNN επιτυγχάνει πιο βαθιά και ισχυρή επεξεργασία των χαρακτηριστικών σε κάθε Block (2 Conv layers αντί για 1), καλύτερη γενίκευση λόγω των dropout και του batch normalization και πιο σταθερή εκπαίδευση με λιγότερο overfitting.

**ΣΥΝΟΨΙΖΟΝΤΑΣ:**

**Επίδραση του αριθμού δεδομένων στην απόδοση του μοντέλου:** <br>
Είναι γνωστό ότι όσο περισσότερα δεδομένα υπάρχουν για την εκπαίδευση ενός νευρωνικού δικτύου, τόσο καλύτερα αποτελέσματα επιστρέφει καθώς εκπαιδεύεται σε ένα μεγαλύτερο πλήθος από features και αποφεύγει καλύτερα το overfitting.

**Επίδραση του αλγορίθμου βελτιστοποίησης:** <br>
Ο αλγόριθμος βελτιστοιποίησης παίζει πολύ σημαντικό ρόλο στην απόδοση του μοντέλου, όπως ακριβώς είδαμε με την αποτυχία του SGD στο LeNet. Η επιλογή του καταλληλότερου ποικίλει ανάλογα το νευρωνικό δίκτυο, και δεν είναι δεδομένη. Σε εμάς, μετά από δοκιμές καταλήξαμε στο καλύτερο μοντέλο μας να έχει σαν αλγόριθμο βελτιστοποίησης τον SGD.

**Επίδραση του μεγέθους παρτίδας (batch size):** <br>
Ύστερα από δοκιμές που πραγματοποιήσαμε, μικρότερο batch size φάνηκε να δίνει καλύτερα αποτελέσματα. Βέβαια, το trade-off που προέκυψε με το μικρό batch size, και συνεπώς την συχνότερη ανανέωση των βαρών, ήταν η αύξηση του χρόνου εκπαίδευσης.

Το χειρότερο μοντέλο αποδείχθηκε να είναι το **LeNet** όπως άλλωστε περιμέναμε, καθώς υλοποιήθηκε αρκετά παλαιότερα από τα άλλα 2 (χωρίς να λαμβάνουμε υπόψιν το δικό μας), τότε που δεν υπήρχαν ούτε οι υπολογιστικοί πόροι ούτε μεγάλα datasets.

Το καλύτερο μοντέλο εκ των τριών που διαβάσαμε στα papers αποδείχθηκε να είναι το **AlexNet**, το οποίο είναι αρκετά μεγαλύτερο του LeNet. Το **VGG** δεν απέχει πολύ από το AlexNet σε accuracy. Το VGG άλλωστε βασίστηκε πολύ στην μορφή που έχει το AlexNet και εξελίχθηκε σε βαθύτερο δίκτυο.

Συνολικά το καλύτερο μοντέλο είναι το **MYCNN_2** με *val accuracy: 0.6780* (με SGD).

**Σχετικά με το F1 Score:**

Το Precision πρακτικά απαντάει το ερώτημα: " *Από όσες φορές το μοντέλο είπε ναι, πόσες φορές είχε δίκιο;* "

Το Recall πρακτικά απαντάει το ερώτημα: " *Από όλες τις πραγματικές θετικές περιπτώσεις, πόσες βρήκε το μοντέλο;* "

Το F1 Score είναι αυτό τελικά που απαντάει το ερώτημα: " *Πόσο καλά ισορροπεί το Precision και το Recall;* "

## Ερώτημα 2
---
### Βήμα 1: Έλεγχος υπερεκπαίδευσης

Για μοντέλο σας  (**MyCNN**) και μόνο, δοκιμάστε διάφορους συνδυασμούς των ακόλουθων τεχνικών για τον έλεγχο της υπερεκπαίδευσης (overfitting), ώστε το μοντέλο σας να γενικεύει καλύτερα, όπως:

- Dropout ([Dropout](https://www.tensorflow.org/tutorials/images/classification#dropout))

- Επαύξηση δεδομένων ([Data augmentation](https://www.tensorflow.org/tutorials/images/classification#data_augmentation), [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#class_imagedatagenerator))

---
### Βήμα 2: Αξιολόγηση
Αξιολογήστε τα αποτελέσματά σας, βάσει του F1 score για το σύνολο επικύρωσης και για το σύνολο ελέγχου

---

**Απάντηση:**

- **Dropout**

Η τεχνική **Dropout** έχει ήδη εφαρμοστεί στο μοντέλο μας και αποτελεί μια μέθοδο regularization (κανονικοποίησης) που χρησιμοποιείται για την αποφυγή της υπερεκπαίδευσης (overfitting). Κατά την διάρκεια της εκπαίδευσης αυτό που κάνει είναι να 'απενεργοποιεί' τυχαία ένα ποσοστό των νευρώνων σε κάθε forward pass, έτσι ώστε το δίκτυο να μην εξαρτάται από ορισμένους μόνο νευρώνες. Έτσι εξαναγκάζει το δίκτυο να μαθαίνει πιο γενικευμένα χαρακτηριστικά. Το dropout λαμβάνει χώρα μόνο κατά την εκπαίδευση του μοντέλου, ενώ κατά την αξιολόγηση/πρόβλεψη όλοι οι νευρώνες είναι ενεργοί.

- **Data Augmentation**

Ακολουθεί η εφαρμογή της τεχνικής **Data augmentation** η οποία συμβάλει στην δημιουργία νέων, ελαφρώς τροποποιημένων δειγμάτων από τα υπάρχοντα δεδομένα, χωρίς να χρειάζεται να συλλέξει νέα. Και αυτή η τεχνική αποτρέπει την υπερπροσαρμογή του μοντέλου, καθώς αυτό ΔΕΝ 'απομνημονεύει' τα δεδομένα, αλλά μαθαίνει να γενικεύει. Το μοντέλο γίνεται λιγότερο ευαίσθητο σε μικρές αλλαγές κλίμακας, περιστροφής κλπ, και τέλος, το μοντέλο μας προπονείται με μεγαλύτερο αριθμό δεδομένων χωρίς νέα συλλογή (η αύξηση αφείλεται καθαρά στα υπάρχοντα δείγματα που έχουν υποστεί ελαφρές μετατοπίσεις κλπ).
"""

from tensorflow import keras
from tensorflow.keras import layers, models

data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal", input_shape=(32, 32, 3)),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
])

def MyCNN_2_DropoutAndDaraAugm():
    model = models.Sequential([
        data_augmentation,

        # Block 1
        layers.Conv2D(64, 3, padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(64, 3, padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=2),
        layers.Dropout(0.25),

        # Block 2
        layers.Conv2D(128, 3, padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(128, 3, padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=2),
        layers.Dropout(0.25),

        # Block 3
        layers.Conv2D(256, 3, padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=2),
        layers.Dropout(0.4),

        # Fully Connected
        layers.Flatten(),
        layers.Dense(512, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(20)  # Output layer (no softmax if using from_logits=True)
    ])
    return model

model = MyCNN_2_DropoutAndDaraAugm()
model.compile(optimizer='SGD',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

metrics_callback = MetricsCallback(validation_data=(x_val, y_val_to20))

history = model.fit(
    x_train, y_train_to20, epochs=50, batch_size=10, validation_data=(x_val, y_val_to20), callbacks=[metrics_callback]
    )

plt.figure(figsize=(10, 6))
plt.plot(metrics_callback.f1_scores, label='F1 Score (macro)', marker='o')
plt.plot(metrics_callback.precision_scores, label='Precision (macro)', marker='s')
plt.plot(metrics_callback.recall_scores, label='Recall (macro)', marker='^')
plt.title('F1 / Precision / Recall over Epochs with SGD')
plt.xlabel('Epoch')
plt.ylabel('Score')
plt.legend()
plt.grid(True)
plt.show()

"""**ΣΧΟΛΙΑΣΜΟΣ ΑΠΟΤΕΛΕΣΜΑΤΩΝ**

Ήδη από πριν είχαμε δει ότι με εφαρμογή πιο προσεγμένου *dropout* το δίκτυό μας, *MyCNN_2*, παρείχε καλύτερα αποτελέσματα από το *MyCNN*, το οποίο είχε μοναδικό dropout πριν την έξοδο. Αυτό γιατί το dropout είναι μια τεχνική ομαλοποίησης, *όπως έχουμε ήδη αναφέρει παραπάνω*, η οποί συμβάλει στην αποφυγή της υπερπροσαρμογής.

Με επιπλέον προσθήκη της τεχνικής *data augmentation* δεν έχουμε αισθητή βελτίωση, κάτι που κανονικά δεν θα έπρεπε να συμβαίνει. Αυτό μπορεί να οφείλεται στο γεγονός ότι έχουμε ήδη ένα μικρό μέρος του dataset για να εκπαιδεύσουμε το μοντέλο με αποτέλεσμα τροποποίηση στα δεδομένα μέσω data augmentation να μην συμβάλει ικανοποιητικά στην βελτίωση της εκπαίδευσης. Επιπλέον, ενδέχεται οι παραμορφώσεις που επιλέξαμε να κάνουμε να μην ήταν ικανοποιητικές για το μοντέλο και να παραποίησαν αρκούντως πολύ τα δεδομένα ώστε στην ουσία να μην συμβάλλουν θετικά στην εκπαίδευση. Το F1 Score ωστόσο παραμένει αρκετά ψηλά, ίσο με *0.6554*, αντί για *0.6909* που είχαμε με απλό dropout ενσωματωμένο μόνο. Και τα δυο υπερνικούν το αρχικό μας μοντέλο χωρίς dropout και data augmentation.

**Πειραματισμός με επιπλέον διαφορετικές τεχνικές για την αποφυγή overfitting**
"""

from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

early_stopping = EarlyStopping(
    monitor='val_loss',        # Check the validation loss
    patience=7,                # Wait 7 epochs before terminating
    restore_best_weights=True  # Restore best weights so far
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,              # Reduce learning rate to the half
    patience=3,              # If not better results for 3 epochs
    min_lr=1e-6              # Minimum
)

model2 = MyCNN_2_DropoutAndDaraAugm()
model2.compile(optimizer='SGD',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

metrics2_callback = MetricsCallback(validation_data=(x_val, y_val_to20))

history2 = model2.fit(
    x_train, y_train_to20, epochs=50, batch_size=10, validation_data=(x_val, y_val_to20), callbacks=[metrics2_callback]
    )

plt.figure(figsize=(10, 6))
plt.plot(metrics2_callback.f1_scores, label='F1 Score (macro)', marker='o')
plt.plot(metrics2_callback.precision_scores, label='Precision (macro)', marker='s')
plt.plot(metrics2_callback.recall_scores, label='Recall (macro)', marker='^')
plt.title('F1 / Precision / Recall over Epochs with SGD')
plt.xlabel('Epoch')
plt.ylabel('Score')
plt.legend()
plt.grid(True)
plt.show()

"""**ΣΧΟΛΙΑΣΜΟΣ ΑΠΟΤΕΛΕΣΜΑΤΩΝ:**

Εδώ πειραματιστήκαμε και με δυο επιπλέον τενικές βελτιστοποίησης, την **Early Stopping** και την **Reduce Learning Rate**.

Η πρώτη είναι μια τεχνική τακτικής διακοπής της εκπαίδευσης ενός νευρωνικού δικτύου όταν η απόδοση στο validation set σταματά να βελτιώνεται. Στόχος της είναι να προλάβουμε το overfitting, δηλαδή να μην συνεχίσει η εκπαίδευση αφού το μοντέλο έχει ήδη φτάσει το καλύτερο σημείο σε απόδοση στο validation set. Έτσι εξοικονομούμε τόσο χρόνο εκπαίδευσης, συμβάλλοντας ταυτόχρονα στην βελτίωση της γενίκευσης του μοντέλου σε νέα δεδομένα (που δεν έχει προλάβει να δει λόγω early stopping).

Η δεύτερη εφαρμόζεται κατά την διάρκεια εκπαίδευσης ενός νευρωνικού δικτύου, και χρησιμοποιείται γι ανα βοηθήσει το μοντέλο να συγκλίνει πιο αποτελεσματικά ειδικά όταν η εκπαίδευση 'κολλάει' ή το validation accuracy δεν βελτιώνεται. Αυτό που κάνει ουσιαστικά είναι να μειώνει το learning rate του optimizer, όταν η απόδοση στο validation set σταματάει να βελτιώνεται.

Αυτό που **παρατηρήσαμε** είναι ότι δεν πέφτει ποτέ σε early stop κάτι που έχει να κάνει με τις παραμέτρους που έχουμε ορίσει και το threshold που το αφήνουμε να έχει προτού αποφασίσει ότι δεν έχουμε άλλη βελτίωση άρα τερμάτισε. Στην εποχή 50 το F1 Score καταλήγει να είναι *0.6367*, χωρίς σημαντική βελτίωση από προηγουμένως.

## Ερώτημα 3
---
### Βήμα 1: Μεταφορά γνώσης
Εφαρμόστε μεταφορά γνώσης (transfer learning) στο δικό σας μοντέλο (**MyCNN**), που αξιολογήσατε ως καλύτερο προς το F1 score στην αντιμετώπιση της υπερεκπαίδεσης.

Για το transfer learning, επιλέξτε το [VGG19](https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg19)  και το [EfficientNetB0](https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/EfficientNetB0) για μεταφορά μάθησης.

α. "Παγώστε" τη συνελικτική βάση και εκπαιδεύστε την κεφαλή ταξινόμησης (classification head - σημαία trainable = False).  

β. Εκπαιδέστε μόνο ένα ποσοστό των επιπέδων, το οποίο βρίσκεται προς την έξοδο του δικτύου. Οι σημαίες trainable εδώ θα πρέπει να οριστούν ανά επίπεδο.

---
### Βήμα 2: Αξιολόγηση

Αξιολογήστε τα αποτελέσματά σας, βάσει του F1 score για το σύνολο επικύρωσης και για το σύνολο ελέγχου.

---

**Απάντηση:** Το μοντέλο που θα χρησιμοποιήσουμε δεν περιέχει τις τεχνικές *Early Stopping* και *Reduce Learning Rate*.

- Βήμα 1
"""

# Pre-trained models
pretrained_model_VGG = tf.keras.applications.VGG19(input_shape=(224,224,3), include_top=False)
pretrained_model_EfficientNet = tf.keras.applications.efficientnet.EfficientNetB0(input_shape=(224,224,3), include_top=False)
pretrained_model_VGG.trainable = False
pretrained_model_EfficientNet.trainable=False

# Create a MyCNN_2 model variant using the pre-trained model as a base
def MyCNN_with_transfer_learning(pretrained_model):
  base_model = pretrained_model

  # Freeze the convolutional base
  base_model.trainable = False

  model = models.Sequential([
      base_model, # The pre-trained convolutional base

      # Fully Connected
      layers.Flatten(),
      layers.Dense(512, activation='relu'),
      layers.BatchNormalization(),
      layers.Dropout(0.5),
      layers.Dense(20)
  ])
  return model

print("Layer Output Shapes:")
forVGG19 = tf.random.uniform((1, 224, 224, 3))
for layer in MyCNN_with_transfer_learning(pretrained_model_VGG).layers:
  forVGG19 = layer(forVGG19)
  print(f"{layer.__class__.__name__:<20} output shape:\t{forVGG19.shape}")

print("Layer Output Shapes:")
forEfficientNteB0 = tf.random.uniform((1, 224, 224, 3))
for layer in MyCNN_with_transfer_learning(pretrained_model_EfficientNet).layers:
  forEfficientNteB0 = layer(forEfficientNteB0)
  print(f"{layer.__class__.__name__:<20} output shape:\t{forEfficientNteB0.shape}")

# Compile using the VGG19 (32x32x3 input images)
model_part3_vgg19 = MyCNN_with_transfer_learning(pretrained_model_VGG)
model_part3_vgg19.compile(optimizer='SGD',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

metrics_part3_vgg19_callback = MetricsCallback(validation_data=(x_val, y_val_to20))

history_part3 = model_part3_vgg19.fit(
    x_train, y_train_to20, epochs=50, batch_size=10, validation_data=(x_val, y_val_to20), callbacks=[metrics_part3_vgg19_callback]
    )

plt.figure(figsize=(10, 6))
plt.plot(metrics_part3_vgg19_callback.f1_scores, label='F1 Score (macro)', marker='o')
plt.plot(metrics_part3_vgg19_callback.precision_scores, label='Precision (macro)', marker='s')
plt.plot(metrics_part3_vgg19_callback.recall_scores, label='Recall (macro)', marker='^')
plt.title('F1 / Precision / Recall over Epochs with VGG19 pre-trained model')
plt.xlabel('Epoch')
plt.ylabel('Score')
plt.legend()
plt.grid(True)
plt.show()

# Compile using the VGG19
model_part3_vgg19 = MyCNN_with_transfer_learning(pretrained_model_VGG)
model_part3_vgg19.compile(optimizer='SGD',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

metrics_part3_vgg19_callback = MetricsCallback(validation_data=(x_val_resized, y_val_to20))

history_part3 = model_part3_vgg19.fit(
    x_train_resized, y_train_to20, epochs=15, batch_size=10, validation_data=(x_val_resized, y_val_to20), callbacks=[metrics_part3_vgg19_callback]
    )

plt.figure(figsize=(10, 6))
plt.plot(metrics_part3_vgg19_callback.f1_scores, label='F1 Score (macro)', marker='o')
plt.plot(metrics_part3_vgg19_callback.precision_scores, label='Precision (macro)', marker='s')
plt.plot(metrics_part3_vgg19_callback.recall_scores, label='Recall (macro)', marker='^')
plt.title('F1 / Precision / Recall over Epochs with VGG19 pre-trained model')
plt.xlabel('Epoch')
plt.ylabel('Score')
plt.legend()
plt.grid(True)
plt.show()

# Compile using the EfficientNetB0
model_part3_EfficientNetB0 = MyCNN_with_transfer_learning(pretrained_model_EfficientNet)
model_part3_EfficientNetB0.compile(optimizer='SGD',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

metrics_part3_EfficientNetB0_callback = MetricsCallback(validation_data=(x_val_resized, y_val_to20))

history_part3 = model_part3_EfficientNetB0.fit(
    x_train_resized, y_train_to20, epochs=15, batch_size=10, validation_data=(x_val_resized, y_val_to20), callbacks=[metrics_part3_EfficientNetB0_callback]
    )

plt.figure(figsize=(10, 6))
plt.plot(metrics_part3_EfficientNetB0_callback.f1_scores, label='F1 Score (macro)', marker='o')
plt.plot(metrics_part3_EfficientNetB0_callback.precision_scores, label='Precision (macro)', marker='s')
plt.plot(metrics_part3_EfficientNetB0_callback.recall_scores, label='Recall (macro)', marker='^')
plt.title('F1 / Precision / Recall over Epochs with EfficientNetB0 pre-trained model')
plt.xlabel('Epoch')
plt.ylabel('Score')
plt.legend()
plt.grid(True)
plt.show()

# Compile using the EfficientNetB0 (32x32x3 input)
model_part3_EfficientNetB0 = MyCNN_with_transfer_learning(pretrained_model_EfficientNet)
model_part3_EfficientNetB0.compile(optimizer='SGD',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

metrics_part3_EfficientNetB0_callback = MetricsCallback(validation_data=(x_val_resized, y_val_to20))

history_part3 = model_part3_EfficientNetB0.fit(
    x_train_resized, y_train_to20, epochs=15, batch_size=10, validation_data=(x_val_resized, y_val_to20), callbacks=[metrics_part3_EfficientNetB0_callback]
    )

plt.figure(figsize=(10, 6))
plt.plot(metrics_part3_EfficientNetB0_callback.f1_scores, label='F1 Score (macro)', marker='o')
plt.plot(metrics_part3_EfficientNetB0_callback.precision_scores, label='Precision (macro)', marker='s')
plt.plot(metrics_part3_EfficientNetB0_callback.recall_scores, label='Recall (macro)', marker='^')
plt.title('F1 / Precision / Recall over Epochs with EfficientNetB0 pre-trained model')
plt.xlabel('Epoch')
plt.ylabel('Score')
plt.legend()
plt.grid(True)
plt.show()

"""**ΣΧΟΛΙΑΣΜΟΣ ΑΠΟΤΕΛΕΣΜΑΤΩΝ**

Αυτό που παρατηρούμε είναι ότι κανένα από τα δυο pre-trained μοντέλα δεν δίνουν στο μοντέλο μας καλύτερο αποτέλεσμα F1 score. Το EfficientNetB0 δεν προσφέρει κανένα καλό χαρακτηριστικό, ίσα ίσα που η F1 score μετρική καταλήγει να είναι πολύ μικρότερη του 10%. To VGG19 δίνει καλά αποτελέσματα σε σύγκριση με το άλλο προ-εκπαιδευμένο μοντέλο. Ωστόσο ούτε αυτού η μετρική f1 score ίση με *0.5506* υπερνικά του απλού μας μοντέλου με dropout και data augmentation. Αυτό δεν ήταν κάτι που περιμέναμε, ωστόσο μπορεί το training dataset με το οποίο έχουν προεκπαιδευτεί τα μοντέλα να μην καλύπτει ικανοποιητικά το subset του dataset CIFAR-100 που κληθήκαμε να χρησιμοποιήσουμε εμείς (με διαφορετικό seed κάθε φοιτητής).

Δοκιμάσαμε, επιπλέον, δυο προσεγγίσεις. Συγκεκριμένα, η τιμή f1 score ιση με 0.5506 αντιστοιχεί στο μοντέλο με είσοδο εικόνες μεγέθους 224x224x3 έναντι του f1 score ίσο με 0.4937 που αντιστοιχεί στο μοντέλο με είσοδο εικόνες μεγέθους 32x32x3. Αυτό είναι λογικό καθώς τα προεκπαιδευμένα μοντέλα έχουν εκπαιδευτεί με εισόδους εικόνες μεγέθους 224x224x3 και άρα τα βάρη ανταποκρίνονται καλύτερα σε αυτά τα μεγέθοι. Τα features που γνωρίζουν τα μοντέλα, και δεδομένου ότι έχουμε εφαρμόσει freeze (δεν επανεκπαιδεύονται τα Layers τους), καλύτερη απόδοση έχουμε όσο πιο κοντά είναι τα δεδομένα μας στο σύνολο δεδομένων με το οποίο εκπαιδεύτηκαν.

- Βήμα 2
"""

def unfreeze_last_20_percent(model): # Fine-20
    total_layers = len(model.layers)

    # Freeze the first 80% of the layers
    for layer in model.layers[:int(total_layers * 0.8)]:
        layer.trainable = False

    # Unfreeze the last 20% of the layers
    for layer in model.layers[int(total_layers * 0.8):]:
        layer.trainable = True

    return model

"""Λόγω απουσίας πόρων και επειδή είχα τρέξει αρχικά τα training με input 32x32x3 παραμένουν αυτά τα αποτελέσματα για 50 εποχές."""

# Pre-trained models
pretrained_model_VGG = tf.keras.applications.VGG19(input_shape=(32,32,3), include_top=False)
pretrained_model_EfficientNet = tf.keras.applications.efficientnet.EfficientNetB0(input_shape=(32,32,3), include_top=False)
pretrained_model_VGG.trainable = False
pretrained_model_EfficientNet.trainable=False

# Create a MyCNN_2 model variant using the pre-trained model as a base
# For pre-trained model VGG19 that has almost 23 layers
def MyCNN_with_transfer_learning_VGG():
  base_model = pretrained_model_VGG
  base_model = unfreeze_last_20_percent(base_model)

  model = models.Sequential([
      base_model,

      # Fully Connected
      layers.Flatten(),
      layers.Dense(512, activation='relu'),
      layers.BatchNormalization(),
      layers.Dropout(0.5),
      layers.Dense(20)
  ])
  return model

# Compile using the VGG19 and reduced layers for training
model_vgg19 = MyCNN_with_transfer_learning_VGG()
model_vgg19.compile(optimizer='SGD',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

metrics_vgg19_callback = MetricsCallback(validation_data=(x_val, y_val_to20))

history_vgg19 = model_vgg19.fit(
    x_train, y_train_to20, epochs=15, batch_size=10, validation_data=(x_val, y_val_to20), callbacks=[metrics_vgg19_callback]
    )

plt.figure(figsize=(10, 6))
plt.plot(metrics_vgg19_callback.f1_scores, label='F1 Score (macro)', marker='o')
plt.plot(metrics_vgg19_callback.precision_scores, label='Precision (macro)', marker='s')
plt.plot(metrics_vgg19_callback.recall_scores, label='Recall (macro)', marker='^')
plt.title('F1 / Precision / Recall over Epochs with VGG19 pre-trained model (reduced training layers)')
plt.xlabel('Epoch')
plt.ylabel('Score')
plt.legend()
plt.grid(True)
plt.show()

# Create a MyCNN_2 model variant using the pre-trained model as a base
# For pre-trained model EfficientNetB0 that has almost 239 layers
def MyCNN_with_transfer_learning_EfficientNetB0():
  base_model = pretrained_model_EfficientNet
  base_model = unfreeze_last_20_percent(base_model)

  model = models.Sequential([
      base_model,

      # Fully Connected
      layers.Flatten(),
      layers.Dense(512, activation='relu'),
      layers.BatchNormalization(),
      layers.Dropout(0.5),
      layers.Dense(20)
  ])
  return model

# Compile using the EfficientNetB0
model_EfficientNetB0 = MyCNN_with_transfer_learning_EfficientNetB0()
model_EfficientNetB0.compile(optimizer='SGD',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

metrics_EfficientNetB0_callback = MetricsCallback(validation_data=(x_val, y_val_to20))

history_efficientnetb0 = model_EfficientNetB0.fit(
    x_train, y_train_to20, epochs=15, batch_size=10, validation_data=(x_val, y_val_to20), callbacks=[metrics_EfficientNetB0_callback]
    )

plt.figure(figsize=(10, 6))
plt.plot(metrics_EfficientNetB0_callback.f1_scores, label='F1 Score (macro)', marker='o')
plt.plot(metrics_EfficientNetB0_callback.precision_scores, label='Precision (macro)', marker='s')
plt.plot(metrics_EfficientNetB0_callback.recall_scores, label='Recall (macro)', marker='^')
plt.title('F1 / Precision / Recall over Epochs with EfficientNetB0 pre-trained model (reduced training layers)')
plt.xlabel('Epoch')
plt.ylabel('Score')
plt.legend()
plt.grid(True)
plt.show()

"""**ΣΧΟΛΙΑΣΜΟΣ ΑΠΟΤΕΛΕΣΜΑΤΩΝ**

Παρόμοια με πριν, το μοντέλο μας εφαρμόζοντας του το pre-trained μοντέλο EfficientNetB0 βγάζει εξίσου άσχημα αποτελέσματα ακόμα και όταν του προσθέτουμε ορισμένα layers στην διαδικασία εκπαίδευσης.

Εφαρμόζοντας το pre-trained μοντέλο VGG19 βγάζουμε αρκετά καλύτερα αποτελέσματα από ότι προηγουμένως, με βελτιωμένο f1 score, ίσο με *0.6163*. Σαφώς καλύτερο αποτέλεσμα, χωρίς όμως να είναι βέλτιστο. Παρατηρούμε, επίσης, ότι το μοντέλο έχει υπερπροσαρμοστεί.

Τα βασικά πλεονεκτήματα της μεθόδου **transfer learning** είναι ότι χρησιμοποιώντας ένα ήδη εκπαιδευμένο μοντέλο ως βάση για το δικό μας, ενσωματώνοντας μόνο το FC επίπεδο, **επιταχύναμε σημαντικά την σύγκλιση της εκπαίδευσης** που εκτελέσαμε. Συγκεκριμένα, το μοντέλο ξεκινάει ήδη από 'έξυπνα' βάρη, καθώς τα μοντέλα αυτά έχουν ήδη μάθει τα χρήσιμα χαρακτηριστικά από τεράστια datasets. Επομένως, το μοντέλο μας δεν χρειάζεται να επαναλάβει αυτή την γνώση από το μηδέν. Ένα ακόμα πλεονέκτημα της μεθόδου αυτής είναι ότι έχουμε **καλύτερη γενίκευση σε μικρότερα dataset**. Σε λίγα δεδομένα, όπως στην δική μας περίπτωση, η μεταφορά γνώσης βοηθάει στην αποφυγή του overfitting, ειδικά όταν το dataset με το οποίο έχει προεκπαιδευτεί το μοντέλο μοιάζει με το δικό μας.

**Διαφορά μεταξύ Freeze και Fine-tuning:** <br>
- Freeze: Τα επίπεδα του προ-εκπαιδευμένου μοντέλου παραμένουν μη-εκπαιδεύσιμα, διατηρώντας τα βάρη με τα οποία έχουν προεκπαιδευτεί.

- Fine-tuning: Ξεπαγώνουμε μερικά ή όλα τα επίπεδα του προεκπαιδευμένου μοντέλου και τα εκπαιδεύουμε ξανά, επιτρέποντας στο μοντέλο να μάθει από τα νέα δεδομένα και να προσαρμοστεί καλύτερα στο νέο dataset.

## Διαχείριση μνήμης (TFRecord)
Η φόρτωση δεδομένων με τον τρόπο που το κάναμε παραπάνω στο απλό παράδειγμα υλοποίησης είναι πολύ βολική αλλά δεν είναι αποτελεσματική ως προς τη διαχείριση της μνήμης. Συγκεκριμένα, με τον τρόπο αυτό, τα δεδομένα αποθηκεύονται απευθείας σε μεταβλητές, οι οποίες όλες μαζί καταλαμβάνουν τη RAM της CPU ή της GPU, κάτι που κάνει αδύνατη τη διαχείριση μεγάλων datasets ή τον μεταχηματισμό των δεδομένων όπως όταν κάνουμε αύξηση δεδομένων (data augmentation).

Για να παρακαμφθεί αυτό το πρόβλημα, υπάρχει η δυνατότητα της σειριοποίησης των δεδομένων (serialization) και της αποθήκευσής τους σε αρχεία μεσαίου μεγέθους (κάποιων MB) τα οποία μπορούν να αναγνωστούν γραμμικά.

Το φορμάτ TFRecord είναι ένα φορμάτ που επιτρέπει την αποθήκευση σειράς δυαδικών εγγραφών. Διαβάστε σχετικά για το [TFRecord and tf.Example](https://www.tensorflow.org/tutorials/load_data/tfrecord) και [tf.data: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data).

Σημειώστε ότι με τη μέθοδο αυτή θα πρέπει να γίνει import η `tensorflow_datasets` και να χρησιμοποιήσουμε την `tfds.load` ώστε να αποθηκευθεί το σύνολο δεδομένων σε αρχεία tfrecord στο δίσκο (δείτε [εδώ](https://colab.research.google.com/github/tensorflow/datasets/blob/master/docs/overview.ipynb) ένα παράδειγμα). Φυσικά μπορούμε να μετατρέψουμε και τα πρωτογενή δεδομένα (raw data) του dataset όπως αρχεία jpg σε φορματ tfrecord όπως [εδώ](https://towardsdatascience.com/working-with-tfrecords-and-tf-train-example-36d111b3ff4d).
"""